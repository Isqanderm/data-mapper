# Automated Benchmark Setup Guide

This guide explains how the automated benchmark system works and how to set it up.

## ğŸ¯ Overview

The project uses **GitHub Actions + github-action-benchmark** to automatically:

1. âœ… Run benchmarks on every PR
2. âœ… Post results as PR comments
3. âœ… Track performance history on GitHub Pages
4. âœ… Alert on performance regressions
5. âœ… Update existing comments (no spam)

## ğŸ“Š What You Get

### On Every Pull Request

Automatic comment with benchmark results:

```
ğŸš€ Performance Benchmark Results

ğŸ“Š om-data-mapper vs class-transformer Comparison

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scenario                                â”‚ Winner       â”‚ Performance     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Simple Transformation                   â”‚ om-data-mapper â”‚ +1370.91% faster â”‚
â”‚ Complex Nested Transformation           â”‚ om-data-mapper â”‚ +4362.85% faster â”‚
â”‚ Array Transformation                    â”‚ om-data-mapper â”‚ +1146.48% faster â”‚
â”‚ Custom Transformation                   â”‚ om-data-mapper â”‚ +1360.77% faster â”‚
â”‚ Exclude/Expose                          â”‚ om-data-mapper â”‚ +569.96% faster â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ¨ om-data-mapper won 5/5 scenarios
âš¡ Average performance improvement: 1762.19%
```

### On Main Branch

- Historical data stored in `gh-pages` branch
- Interactive charts at: `https://isqanderm.github.io/data-mapper/dev/bench/`
- Performance trend tracking over time

## ğŸ› ï¸ Setup Instructions

### 1. Enable GitHub Pages (One-Time Setup)

1. Go to your repository settings
2. Navigate to **Pages** section
3. Under **Source**, select:
   - Branch: `gh-pages`
   - Folder: `/ (root)`
4. Click **Save**

The workflow will automatically create the `gh-pages` branch on the first run.

### 2. Verify Workflow Permissions

Ensure GitHub Actions has write permissions:

1. Go to **Settings** â†’ **Actions** â†’ **General**
2. Scroll to **Workflow permissions**
3. Select **Read and write permissions**
4. Check **Allow GitHub Actions to create and approve pull requests**
5. Click **Save**

### 3. Test the Setup

Create a test PR to verify everything works:

```bash
git checkout -b test-benchmark
git commit --allow-empty -m "test: trigger benchmark"
git push origin test-benchmark
```

Then create a PR and check:
- âœ… Benchmark workflow runs successfully
- âœ… Comment appears on the PR
- âœ… Results are formatted correctly

## ğŸ“ File Structure

```
.github/workflows/
  â””â”€â”€ benchmark.yml          # Main workflow file

benchmarks/suites/compat/
  â”œâ”€â”€ comparison.js          # Human-readable output
  â”œâ”€â”€ comparison-json.js     # JSON output for tracking
  â”œâ”€â”€ models-ct.ts           # class-transformer models
  â”œâ”€â”€ models-om.ts           # om-data-mapper models
  â””â”€â”€ README.md              # Benchmark documentation

package.json
  â””â”€â”€ scripts:
      â”œâ”€â”€ bench:compat       # Run comparison (formatted)
      â””â”€â”€ bench:compat:json  # Run comparison (JSON)
```

## ğŸ”§ How It Works

### Workflow Triggers

The benchmark workflow runs on:

- **Pull Requests** to `main` branch
- **Pushes** to `main` branch
- **Manual trigger** via workflow_dispatch

### Workflow Steps

1. **Checkout code** - Gets the latest code
2. **Setup Node.js** - Installs Node.js 20
3. **Install dependencies** - Runs `npm ci`
4. **Build project** - Compiles TypeScript
5. **Build benchmarks** - Compiles benchmark models
6. **Run benchmarks** - Executes all benchmark suites
7. **Generate JSON** - Creates JSON output for tracking
8. **Store results** - Saves to GitHub Pages (main only)
9. **Comment PR** - Posts results to PR (PRs only)

### Data Storage

- **Main branch**: Results stored in `gh-pages` branch at `dev/bench/`
- **Pull requests**: Results posted as comments only (not stored)

### Performance Alerts

If performance degrades by >150%:

- âš ï¸ Alert comment on commit
- ğŸ“§ Notification to `@Isqanderm`
- âŒ Workflow does NOT fail (configurable)

## ğŸ¨ Customization

### Change Alert Threshold

Edit `.github/workflows/benchmark.yml`:

```yaml
- name: Store benchmark result
  uses: benchmark-action/github-action-benchmark@v1
  with:
    alert-threshold: '150%'  # Change this value
```

### Fail on Performance Regression

```yaml
- name: Store benchmark result
  uses: benchmark-action/github-action-benchmark@v1
  with:
    fail-on-alert: true  # Change to true
```

### Change Benchmark Scenarios

Edit `benchmarks/suites/compat/comparison-json.js` to add/remove scenarios.

### Customize PR Comment Format

Edit the `Comment PR with comparison results` step in `benchmark.yml`.

## ğŸ“ˆ Viewing Historical Data

After the first merge to `main`:

1. Visit: `https://isqanderm.github.io/data-mapper/dev/bench/`
2. View interactive charts
3. Compare performance over time
4. Identify trends and regressions

## ğŸ› Troubleshooting

### Workflow Fails with "Permission Denied"

**Solution**: Enable write permissions in repository settings (see Setup step 2)

### No Comment on PR

**Possible causes**:
1. Workflow didn't run (check Actions tab)
2. Benchmark failed (check workflow logs)
3. Bot doesn't have permission to comment

**Solution**: Check workflow logs for errors

### GitHub Pages Not Working

**Possible causes**:
1. `gh-pages` branch doesn't exist yet
2. GitHub Pages not enabled
3. Wrong branch/folder selected

**Solution**: 
1. Wait for first merge to `main` to create `gh-pages` branch
2. Enable GitHub Pages in settings (see Setup step 1)

### Benchmark Results Look Wrong

**Solution**: 
1. Check if `npm run bench:compat` works locally
2. Verify `comparison-json.js` outputs valid JSON
3. Check workflow logs for errors

## ğŸ”„ Updating Benchmarks

### Add New Scenario

1. Edit `benchmarks/suites/compat/comparison.js`
2. Add new benchmark suite
3. Edit `benchmarks/suites/compat/comparison-json.js`
4. Add corresponding JSON output
5. Update `totalSuites` counter
6. Test locally: `npm run bench:compat:json`

### Remove Scenario

1. Remove from both `comparison.js` and `comparison-json.js`
2. Update `totalSuites` counter
3. Test locally

## ğŸ“š Related Documentation

- [GitHub Action Benchmark](https://github.com/benchmark-action/github-action-benchmark)
- [Benchmark.js Documentation](https://benchmarkjs.com/)
- [GitHub Pages Documentation](https://docs.github.com/en/pages)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)

## ğŸ’¡ Tips

1. **Keep benchmarks fast**: Long-running benchmarks slow down CI
2. **Use meaningful names**: Clear scenario names help identify regressions
3. **Monitor trends**: Check GitHub Pages regularly for performance trends
4. **Test locally first**: Always run `npm run bench:compat` before pushing
5. **Update documentation**: Keep this guide updated when changing benchmarks

## ğŸ¯ Next Steps

After setup is complete:

1. âœ… Merge this PR to `main`
2. âœ… Verify GitHub Pages is accessible
3. âœ… Create a test PR to verify comments work
4. âœ… Monitor performance trends over time
5. âœ… Celebrate automated benchmarking! ğŸ‰

